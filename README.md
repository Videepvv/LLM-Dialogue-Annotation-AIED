# LLM Dialogue Annotation for Educational Discourse

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This repository contains code for automatically annotating educational dialogue using Large Language Models (LLMs), as presented in our AIED 2026 paper.

## ğŸ“‹ Overview

We evaluate LLM performance on three educational dialogue annotation tasks:

| Dataset | Task | Labels | Samples |
|---------|------|--------|---------|
| **TalkMoves** | Teacher talk moves | 7 classes | 150,918 |
| **TalkMoves** | Student talk moves | 5 classes | 52,683 |
| **DELI** | Dialogue type & target | 3 + 6 classes | 14,003 |
| **Weights Task** | CPS facets | 3 binary facets | 2,400 |

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Create conda environment
conda create -n llm-annotation python=3.11 -y
conda activate llm-annotation

# Install dependencies
pip install -r requirements.txt
```

### 2. Download Models from Hugging Face

```bash
# Login to Hugging Face (required for Llama models)
huggingface-cli login

# Download models (example)
python scripts/download_models.py --model llama-8b --output-dir ./models
```

### 3. Download Datasets

```bash
# TalkMoves
git clone https://github.com/AshishJumbo/TalkMoves.git data/TalkMoves

# DELI - Contact authors or download from source
# CPS Weights Task - Included in data/ directory
```

### 4. Run Inference

```bash
# TalkMoves annotation
python src/run_talkmoves.py --model llama-8b --data_type teacher --n_samples 1000

# DELI annotation
python src/run_deli.py --model llama-8b --n_samples 1000

# CPS annotation
python src/run_cps.py --model llama-8b --n_samples 1000
```

### 5. Calculate Metrics

```bash
# Calculate Kappa scores
python src/calculate_kappa.py --dataset talkmoves

# Generate analysis report
python src/analysis.py --all
```

## ğŸ“ Repository Structure

```
LLM-Dialogue-Annotation-AIED/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ run_talkmoves.py      # TalkMoves inference
â”‚   â”œâ”€â”€ run_deli.py           # DELI inference
â”‚   â”œâ”€â”€ run_cps.py            # CPS inference
â”‚   â”œâ”€â”€ calculate_kappa.py    # Kappa calculation
â”‚   â””â”€â”€ analysis.py           # Per-label analysis
â”œâ”€â”€ data/                     # Datasets (download separately)
â”‚   â”œâ”€â”€ TalkMoves/            # TalkMoves dataset
â”‚   â”œâ”€â”€ DeliData/             # DELI dataset
â”‚   â””â”€â”€ WTD/                  # Weights Task dataset
â”œâ”€â”€ results/                  # Output results
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ download_models.py    # Model download helper
â”‚   â””â”€â”€ run_all_models.sh     # Batch inference script
â””â”€â”€ configs/                  # Configuration files
    â””â”€â”€ models.yaml           # Model configurations
```

## ğŸ”§ Supported Models

| Model | HuggingFace ID | Size |
|-------|---------------|------|
| Llama-3.1-8B | `meta-llama/Llama-3.1-8B-Instruct` | ~16GB |
| Mistral-7B | `mistralai/Mistral-7B-Instruct-v0.3` | ~14GB |
| Qwen2.5-7B | `Qwen/Qwen2.5-7B-Instruct` | ~15GB |
| Gemma-2-9B | `google/gemma-2-9b-it` | ~18GB |
| Phi-3.5 | `microsoft/Phi-3.5-mini-instruct` | ~8GB |

## ğŸ“Š Results

### Cohen's Kappa Scores

| Dataset | Task | Best Model | Kappa |
|---------|------|------------|-------|
| TalkMoves | Teacher | Qwen-7B | 0.190 |
| TalkMoves | Student | Llama-8B | 0.446 |
| DELI | Type | Llama-8B | 0.649 |
| DELI | Target | Llama-8B | 0.594 |

### Key Findings

1. **LLMs struggle with pedagogically nuanced labels** (Revoicing, Press for Reasoning)
2. **Surface form vs. function**: Models succeed on labels with explicit markers but fail when the same surface form serves multiple functions
3. **Teacher moves harder than student moves**: Îº gap of ~0.25

## ğŸ“ Usage Examples

### Single Utterance Annotation

```python
from src.annotator import DialogueAnnotator

annotator = DialogueAnnotator(model="llama-8b")

# Teacher talk move
result = annotator.classify_teacher(
    context="Student: The answer is 42",
    utterance="Why do you think that?"
)
print(result)  # {"category": 3, "move": 6, "label": "Press for Reasoning"}
```

### Batch Processing

```python
from src.batch_processor import BatchProcessor

processor = BatchProcessor(model="qwen-7b", dataset="talkmoves")
results = processor.run(split="test", output_path="results/output.json")
```

## ğŸ§® Annotation Schema

### TalkMoves Teacher Labels

| ID | Label | Description |
|----|-------|-------------|
| 0 | Other | Non-instructional talk |
| 1 | Keep Together | Managing attention/turns |
| 2 | Students Relate | Prompting peer engagement |
| 3 | Revoicing | Repeating student contributions |
| 4 | Press Accuracy | Checking correctness |
| 5 | Press Reasoning | Asking for explanations |
| 6 | Challenge | Questioning student ideas |

### DELI Type Labels

| ID | Label | Description |
|----|-------|-------------|
| -1 | None | Off-topic/greetings |
| 0 | Probing | Questions provoking discussion |
| 1 | NPD | Non-probing deliberation |

## ğŸ“– Citation

```bibtex
@inproceedings{author2026llm,
  title={Evaluating LLMs for Educational Dialogue Annotation},
  author={Author, Name},
  booktitle={Proceedings of AIED 2026},
  year={2026}
}
```

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ™ Acknowledgments

- TalkMoves dataset: [Suresh et al., 2022](https://github.com/AshishJumbo/TalkMoves)
- DELI dataset: [Karadzhov et al., 2021](https://github.com/GT-SALT/DELI)
